from fastapi import APIRouter, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session
from database import get_db
from models import Event
import pandas as pd
import ollama
from datetime import datetime, timedelta
import joblib

router = APIRouter()

class ChatRequest(BaseModel):
    message: str

# Model ve Vectorizer'Ä± global olarak yÃ¼kleyelim
try:
    vectorizer = joblib.load("vectorizer.pkl")
    intent_model = joblib.load("intent_model.pkl")
    print("âœ… Intent modeli yÃ¼klendi.")
except Exception as e:
    print(f"âŒ Intent modeli yÃ¼klenemedi: {e}")
    vectorizer = None
    intent_model = None

def get_events_for_today(db_session: Session):
    """BugÃ¼nÃ¼n etkinliklerini getirir (gÃ¼n bazÄ±nda aralÄ±k sorgusu ile)"""
    try:
        today_str = datetime.today().strftime("%Y-%m-%d")
        day_start = datetime.strptime(today_str, "%Y-%m-%d")  # BugÃ¼n 00:00:00
        day_end = day_start + timedelta(days=1)                # Ertesi gÃ¼n 00:00:00
        events = db_session.query(Event).filter(
            Event.date >= day_start,
            Event.date < day_end
        ).all()
        return events
    except Exception as e:
        print(f"âš ï¸ VeritabanÄ± hatasÄ±: {e}")
        return []

def get_response_from_csv(user_message: str) -> str:
    """intents.csv dosyasÄ±ndan doÄŸrudan mesajla eÅŸleÅŸen yanÄ±tÄ± dÃ¶ndÃ¼rÃ¼r."""
    try:
        df = pd.read_csv("intents.csv", encoding="utf-8")
        row = df[df["text"].str.lower() == user_message.lower()]
        if not row.empty:
            return row.iloc[0]["response"]
    except Exception as e:
        print(f"âš ï¸ CSV Okuma HatasÄ±: {e}")
    return None

def classify_with_model(user_message: str):
    """SVM modeliyle intent sÄ±nÄ±flandÄ±rmasÄ± yapar ve (tahmin, gÃ¼ven) dÃ¶ndÃ¼rÃ¼r."""
    if not intent_model or not vectorizer:
        return None, 0.0

    X = vectorizer.transform([user_message])
    predicted_intent = intent_model.predict(X)[0]
    probabilities = intent_model.predict_proba(X)[0]
    confidence = max(probabilities)
    return predicted_intent, confidence

@router.post("/respond", tags=["Chatbot"])
def chatbot_response(request: ChatRequest, db: Session = Depends(get_db)):
    user_message = request.message.lower().strip()
    print("\n=== YENÄ° MESAJ ===")
    print(f"ğŸ“© Gelen mesaj: {user_message}")

    try:
        # 1ï¸âƒ£ Ã–ncelikle takvim sorgusu kontrolÃ¼
        if any(kw in user_message for kw in ["takvim", "ajandam", "izin"]):
            events = get_events_for_today(db)
            if events:
                event_texts = "\n".join([f"- {evt.name} ({evt.start_time})" for evt in events])
                print("ğŸ“… Takvim verileri alÄ±ndÄ±.")
                return {"response": f"ğŸ“… BugÃ¼nkÃ¼ etkinlikler:\n{event_texts}"}
            else:
                print("ğŸ“… BugÃ¼n iÃ§in etkinlik bulunamadÄ±.")
                # Takvim sorgusu var ama veri yoksa devam ediyoruz, model kontrol edilecek.
        
        # 2ï¸âƒ£ Model ile intent sÄ±nÄ±flandÄ±rmasÄ±
        predicted_intent, confidence = classify_with_model(user_message)
        print(f"ğŸ” Model Tahmini: {predicted_intent}, GÃ¼ven: {confidence:.2f}")
        threshold = 0.50  # GÃ¼ven eÅŸiÄŸi

        if confidence >= threshold:
            # Intent'e gÃ¶re yanÄ±tlarÄ± belirleyin
            intent_responses = {
                "izin_sorgulama": "Takviminizde izin bilgisi bulunuyor: [DetaylÄ± veriler].",
                "etkinlik_ekleme": "Etkinlik ekleme iÅŸlemi iÃ§in lÃ¼tfen gerekli bilgileri giriniz.",
                # DiÄŸer intent'ler ve yanÄ±tlar...
            }
            if predicted_intent in intent_responses:
                return {"response": intent_responses[predicted_intent]}
        
        # 3ï¸âƒ£ Modelden yeterli yanÄ±t alÄ±namadÄ±ysa CSV'den yanÄ±t arayalÄ±m
        csv_response = get_response_from_csv(user_message)
        if csv_response:
            print(f"âœ… CSV yanÄ±tÄ±: {csv_response}")
            return {"response": csv_response}

        # 4ï¸âƒ£ Son Ã§are olarak LLM (Ollama) kullanÄ±mÄ±
        print("ğŸ¤– LLM'e yÃ¶nlendiriliyor...")
        try:
            ollama_response = ollama.chat("mistral", [{"role": "user", "content": user_message}])
            print(f"ğŸ”µ LLM Ham YanÄ±t: {ollama_response}")
            if ollama_response and isinstance(ollama_response, dict):
                llm_response = ollama_response.get("message", {}).get("content", "").strip()
                if llm_response:
                    return {"response": llm_response}
        except Exception as e:
            print(f"âš ï¸ LLM HatasÄ±: {e}")

        return {"response": "ÃœzgÃ¼nÃ¼m, bu konuda yardÄ±mcÄ± olamÄ±yorum."}

    except Exception as e:
        print(f"âŒ HATA: {str(e)}")
        return {"response": f"Bir hata oluÅŸtu: {str(e)}"}
